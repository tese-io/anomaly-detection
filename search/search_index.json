{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Anomaly Detection Architecture (Open Docs)","text":"<p>This site documents our anomaly-detection system: high-level architecture, flows, scoring, and implementation notes. It is maintained by Tese.io and open to community contributions.</p>"},{"location":"index.html#overview","title":"Overview","text":"<p>This document outlines the architecture for an anomaly detection system designed to validate metric catalog records against supporting documents. The system processes two primary inputs:</p> <ol> <li>Metric Catalog Record: Contains question information (ID, question, answer, metadata)</li> <li>Supporting Files: Documents in various formats (PDF, DOC, XLSX, images, etc.)</li> </ol>"},{"location":"index.html#system-objectives","title":"System Objectives","text":"<p>The architecture aims to detect three types of anomalies:</p> <ol> <li>Text-based Anomaly Detection: Analyze historical answers for the same question to identify if the current answer is anomalous</li> <li>Document Tampering Detection: Identify if attached files have been modified or tampered with</li> <li>Answer-Document Consistency: Verify if the provided answer is supported by the content in the attached files</li> </ol>"},{"location":"index.html#output-metrics","title":"Output Metrics","text":"<p>Each anomaly detection produces three scores: - Text Anomaly Score: 0-100 (higher = more anomalous) - Tampering Score: 0-100 (higher = more likely tampered) - Support Score: 0-100 (higher = better supported by documents)</p> <p>Each score includes a detailed text description explaining the reasoning.</p>"},{"location":"index.html#quick-links","title":"Quick Links","text":"<ul> <li>Architecture \u2192 System components and data flow</li> <li>Technology Stack \u2192 Google Document AI + Resistant AI integration</li> <li>Implementation Guide \u2192 Technical implementation details</li> <li>Cost Analysis \u2192 Pricing and optimization strategies</li> <li>API Reference \u2192 Endpoints and response formats</li> </ul>"},{"location":"index.html#getting-started","title":"Getting Started","text":"<ol> <li>Architecture Overview - Understand the system components and data flow</li> <li>Technology Stack - Learn about Google Document AI and Resistant AI integration</li> <li>Implementation Guide - Follow technical implementation steps</li> <li>Cost Analysis - Plan your budget and optimization strategy</li> </ol>"},{"location":"index.html#contributing","title":"Contributing","text":"<p>This documentation is open to community contributions. Please see our Contributing Guide for details on how to contribute to the project.</p>"},{"location":"architecture.html","title":"Architecture","text":""},{"location":"architecture.html#components","title":"Components","text":""},{"location":"architecture.html#1-orchestrator","title":"1. Orchestrator","text":"<p>The central component that coordinates all processing flows and manages the overall workflow.</p> <p>Responsibilities: - Receive and validate input data - Route processing to appropriate flows - Aggregate results from all flows - Generate final anomaly report - Handle error recovery and retries</p>"},{"location":"architecture.html#2-text-analysis-flow","title":"2. Text Analysis Flow","text":"<p>Analyzes the provided answer against historical data for the same question.</p> <p>Components: - Historical Data Retrieval - Statistical Analysis Engine - Pattern Recognition - Anomaly Scoring</p> <p>Process: 1. Retrieve all historical answers for the question ID 2. Perform statistical analysis (mean, standard deviation, outliers) 3. Apply pattern recognition algorithms 4. Generate anomaly score and explanation</p>"},{"location":"architecture.html#3-document-analysis-flow","title":"3. Document Analysis Flow","text":"<p>Processes attached files to detect tampering and extract relevant information.</p> <p>Components: - File Format Detection - Tampering Detection Engine - Content Extraction Engine - Multi-file Correlation</p> <p>Process: 1. Detect file format and validate integrity 2. Perform tampering analysis 3. Extract relevant content and data 4. Correlate information across multiple files</p>"},{"location":"architecture.html#data-flow","title":"Data Flow","text":""},{"location":"architecture.html#input-processing","title":"Input Processing","text":"<pre><code>Input \u2192 Orchestrator \u2192 Validation \u2192 Routing\n</code></pre>"},{"location":"architecture.html#text-analysis-flow","title":"Text Analysis Flow","text":"<pre><code>Question ID \u2192 Historical Data \u2192 Statistical Analysis \u2192 Anomaly Detection \u2192 Score + Description\n</code></pre>"},{"location":"architecture.html#document-analysis-flow","title":"Document Analysis Flow","text":"<pre><code>Files \u2192 Format Detection \u2192 Tampering Check \u2192 Content Extraction \u2192 Answer Validation \u2192 Scores + Descriptions\n</code></pre>"},{"location":"architecture.html#output-generation","title":"Output Generation","text":"<pre><code>All Scores \u2192 Aggregation \u2192 Final Report \u2192 Storage\n</code></pre>"},{"location":"architecture.html#technology-stack","title":"Technology Stack","text":""},{"location":"architecture.html#primary-stack-recommended","title":"Primary Stack (Recommended)","text":""},{"location":"architecture.html#1-google-document-ai","title":"1. Google Document AI","text":"<p>Purpose: Content extraction and OCR Components: - Form Parser: $30/1,000 pages - General purpose extraction - Utility Parser: $0.10 per 10 pages - Specialized for utility bills - Layout Parser: $10/1,000 pages - Text and table extraction - Enterprise OCR: $1.50/1,000 pages - High-accuracy OCR</p> <p>Advantages: - High accuracy across multiple file formats - Specialized processors for different document types - Integration with Google Cloud ecosystem - Scalable pricing model</p>"},{"location":"architecture.html#2-resistant-ai","title":"2. Resistant AI","text":"<p>Purpose: Document tampering detection Integration: Available through Google Cloud Marketplace Features: - Forensic-grade tampering detection - Support for multiple file formats - Real-time analysis (&lt;20 seconds) - Detailed tampering indicators</p> <p>Advantages: - Built specifically for document forensics - Integrates seamlessly with Google Document AI - Provides detailed tampering indicators - Enterprise-grade security</p>"},{"location":"architecture.html#3-custom-ai-agents-llm-based","title":"3. Custom AI Agents (LLM-based)","text":"<p>Purpose: Orchestration, validation, and reasoning Technology: OpenAI GPT-4o-mini or similar Cost: ~$0.15/1M input tokens, $0.60/1M output tokens</p> <p>Responsibilities: - Orchestrate the entire workflow - Perform multi-file reasoning - Generate explanations and citations - Handle edge cases and conflicts</p>"},{"location":"architecture.html#alternative-solutions","title":"Alternative Solutions","text":""},{"location":"architecture.html#why-not-other-frameworks","title":"Why Not Other Frameworks?","text":""},{"location":"architecture.html#taggunveryfiocrolus-limitations","title":"Taggun/Veryfi/Ocrolus Limitations","text":"<ul> <li>Narrow domain focus: Optimized for receipts/invoices, not general documents</li> <li>Limited file format support: Primarily image-based, not PDF/Office files</li> <li>Workflow constraints: Built for specific use cases (expenses, lending)</li> <li>Integration complexity: Not designed for multi-file, multi-format workflows</li> </ul>"},{"location":"architecture.html#advantages-of-resistant-ai-google-document-ai","title":"Advantages of Resistant AI + Google Document AI","text":"<ul> <li>Breadth and depth: Covers all file types with specialized processors</li> <li>Clean separation of concerns: Tampering vs. extraction vs. validation</li> <li>Google Cloud integration: Seamless deployment and scaling</li> <li>Future-proof: Designed for enterprise workflows</li> </ul>"},{"location":"cost-analysis.html","title":"Cost Analysis","text":""},{"location":"cost-analysis.html#overview","title":"Overview","text":"<p>This document provides a comprehensive cost analysis for the anomaly detection system using Google Document AI and Resistant AI. The analysis covers per-document costs, monthly projections, and optimization strategies.</p>"},{"location":"cost-analysis.html#cost-components","title":"Cost Components","text":""},{"location":"cost-analysis.html#1-google-document-ai-extraction","title":"1. Google Document AI (Extraction)","text":"<p>Document AI is billed per page and by processor:</p> <ul> <li>Form Parser (good default for utility bills, tables &amp; key-values): $30 / 1,000 pages (= $0.03/page) for up to 1M pages/month; $20 / 1,000 thereafter</li> <li>Enterprise Document OCR (plain OCR text only): $1.50 / 1,000 pages (= $0.0015/page)</li> <li>Pretrained \"Utility parser\" (if Google grants access): $0.10 per 10 pages (= $0.01/page). Note: limited-access processor\u2014you must request enablement</li> <li>Custom processors (only if you train your own): hosting $0.05/hour per deployed version (in addition to per-page prediction)</li> </ul> <p>What counts as a page: PDF page = 1, image = 1; DOCX up to 3,000 characters = 1 page; XLSX each sheet/tab = 1 page; PPTX each slide = 1 page.</p>"},{"location":"cost-analysis.html#2-resistant-ai-document-forensics-tamperfraud","title":"2. Resistant AI Document Forensics (Tamper/Fraud)","text":"<ul> <li>Pricing is not public; sold via Google Cloud Marketplace / AWS Marketplace and typically quote-based by volume &amp; deployment</li> <li>They provide an ROI calculator but not rates; marketing claims \"&lt;20 seconds\" checks at scale</li> <li>Expect contract pricing, not self-serve</li> </ul>"},{"location":"cost-analysis.html#3-your-ai-agents-llm-calls","title":"3. Your AI Agents (LLM Calls)","text":"<p>Using an efficient OpenAI model (e.g., GPT-4o-mini), public rates are: $0.15 / 1M input tokens and $0.60 / 1M output tokens. Your validation/orchestration prompts are small, so this cost is typically pennies per thousands of runs.</p>"},{"location":"cost-analysis.html#4-object-storage","title":"4. Object Storage","text":"<p>If you use Google Cloud Storage (Standard), reference pricing is about $0.020/GB-month in common US regions (plus tiny request/egress fees).</p>"},{"location":"cost-analysis.html#per-document-cost-examples","title":"Per-Document Cost Examples","text":""},{"location":"cost-analysis.html#scenario-a-3-separate-monthly-bills-3-pages-total","title":"Scenario A: 3 Separate Monthly Bills (3 pages total)","text":"<ul> <li>DocAI (Form Parser): 3 \u00d7 $0.03 = $0.09. If you get access to Utility parser: 3 \u00d7 $0.01 = $0.03</li> <li>Resistant AI: contract-based (TBD with vendor)</li> <li>Your agents (LLM): example 16k input + 4k output tokens \u2192 (0.016\u00d7$0.15) + (0.004\u00d7$0.60) \u2248 $0.0048</li> <li>Storage: ~3 MB kept \u2192 \u2248 $0.00006/month at $0.020/GB</li> </ul>"},{"location":"cost-analysis.html#scenario-b-only-12-bills-uploaded-12-pages","title":"Scenario B: Only 1\u20132 Bills Uploaded (1\u20132 pages)","text":"<ul> <li>DocAI (Form Parser): $0.03\u2013$0.06 (or $0.01\u2013$0.02 via Utility parser)</li> <li>Resistant AI: contract-based</li> <li>LLM + storage: roughly proportional (tiny)</li> </ul>"},{"location":"cost-analysis.html#scenario-c-one-bill-with-usage-history-table-1-page","title":"Scenario C: One Bill with Usage History Table (1 page)","text":"<ul> <li>DocAI (Form Parser): $0.03 (or $0.01 with Utility parser)</li> <li>Resistant AI / LLM / storage: as above</li> </ul> <p>If your bills average 2 pages, double the DocAI portion. XLSX with 3 tabs counts as 3 pages; a DOCX over 3,000 chars spills into multiple billable \"pages.\"</p>"},{"location":"cost-analysis.html#monthly-cost-projections","title":"Monthly Cost Projections","text":"<p>Assume each verification has 3 one-page bills (3 pages), Form Parser pricing, and our earlier LLM estimate.</p> Monthly Verifications DocAI pages DocAI cost (Form Parser) LLM est. Storage new (GB) Storage cost est. 1,000 3,000 $90 $4.80 ~3 GB $0.06 10,000 30,000 $900 $48 ~30 GB $0.60 100,000 300,000 $9,000 $480 ~300 GB $6.00 <p>(Resistant AI is additional and quote-based.)</p> <p>If you secure access to Utility parser ($0.01/page), the DocAI column drops by ~66%: e.g., 10k verifications would be $300 instead of $900. (Utility parser is limited access; you must apply.)</p>"},{"location":"cost-analysis.html#cost-optimization-strategies","title":"Cost Optimization Strategies","text":""},{"location":"cost-analysis.html#1-processor-selection","title":"1. Processor Selection","text":"<ul> <li>Use Form Parser by default: Most cost-effective for general documents</li> <li>Apply for Utility Parser access: Reduces cost by ~66% for eligible documents</li> <li>Optimize page counts: Avoid unnecessary multi-page scans</li> <li>Cache common prompts: Reduce LLM costs through prompt optimization</li> <li>Storage tiering: Move older data to cheaper storage tiers</li> </ul>"},{"location":"cost-analysis.html#2-batch-processing","title":"2. Batch Processing","text":"<ul> <li>Group similar documents: Process multiple documents in batches</li> <li>Optimize file formats: Use PDFs instead of images when possible</li> <li>Compress files: Reduce storage costs with appropriate compression</li> </ul>"},{"location":"cost-analysis.html#3-volume-discounts","title":"3. Volume Discounts","text":"<ul> <li>Google Document AI: Volume discounts available for high usage</li> <li>Resistant AI: Contract-based pricing with volume tiers</li> <li>OpenAI: Usage-based pricing with potential enterprise discounts</li> </ul>"},{"location":"cost-analysis.html#cost-levers","title":"Cost Levers","text":""},{"location":"cost-analysis.html#immediate-optimizations","title":"Immediate Optimizations","text":"<ol> <li>Use Form Parser by default for most documents</li> <li>Apply for Utility Parser access to reduce costs by 66% for utility bills</li> <li>Optimize page counts by trimming cover pages and unnecessary content</li> <li>Cache common agent prompts to reduce LLM costs</li> <li>Use appropriate storage tiers for different data types</li> </ol>"},{"location":"cost-analysis.html#long-term-optimizations","title":"Long-term Optimizations","text":"<ol> <li>Negotiate volume discounts with Resistant AI through Google/AWS Marketplace</li> <li>Implement intelligent caching for frequently processed documents</li> <li>Use custom processors for specific document types if volume justifies the cost</li> <li>Optimize data retention policies to minimize storage costs</li> </ol>"},{"location":"cost-analysis.html#budget-planning","title":"Budget Planning","text":""},{"location":"cost-analysis.html#startup-phase-1000-documentsmonth","title":"Startup Phase (1,000 documents/month)","text":"<ul> <li>Document AI: $90</li> <li>LLM: $4.80</li> <li>Storage: $0.06</li> <li>Resistant AI: Contract-based (estimate $100-500/month)</li> <li>Total: ~$200-600/month</li> </ul>"},{"location":"cost-analysis.html#growth-phase-10000-documentsmonth","title":"Growth Phase (10,000 documents/month)","text":"<ul> <li>Document AI: $900</li> <li>LLM: $48</li> <li>Storage: $0.60</li> <li>Resistant AI: Contract-based (estimate $1,000-5,000/month)</li> <li>Total: ~$2,000-6,000/month</li> </ul>"},{"location":"cost-analysis.html#scale-phase-100000-documentsmonth","title":"Scale Phase (100,000 documents/month)","text":"<ul> <li>Document AI: $9,000</li> <li>LLM: $480</li> <li>Storage: $6.00</li> <li>Resistant AI: Contract-based (estimate $10,000-50,000/month)</li> <li>Total: ~$20,000-60,000/month</li> </ul>"},{"location":"cost-analysis.html#roi-considerations","title":"ROI Considerations","text":""},{"location":"cost-analysis.html#cost-per-document-analysis","title":"Cost per Document Analysis","text":"<ul> <li>Form Parser path: ~$0.031 + Resistant AI cost</li> <li>Utility Parser path: ~$0.101 + Resistant AI cost</li> <li>LLM costs: ~$0.001\u20130.002 per document</li> <li>Storage: ~$0.00002\u20130.00005 per month</li> </ul>"},{"location":"cost-analysis.html#value-proposition","title":"Value Proposition","text":"<ul> <li>Automated fraud detection reduces manual review costs</li> <li>High accuracy minimizes false positives and negatives</li> <li>Scalable processing handles high volumes efficiently</li> <li>Audit trail provides compliance and transparency</li> </ul>"},{"location":"cost-analysis.html#conclusion","title":"Conclusion","text":"<p>The anomaly detection system provides cost-effective document validation with clear pricing models for most components. The main variable cost is Resistant AI, which requires contract negotiation but provides enterprise-grade fraud detection capabilities.</p> <p>Key recommendations: 1. Start with Form Parser for cost efficiency 2. Apply for Utility Parser access to reduce costs by 66% 3. Negotiate volume discounts with Resistant AI 4. Implement caching and optimization strategies 5. Monitor costs and adjust strategies based on actual usage patterns</p>"},{"location":"implementation.html","title":"Implementation Guide","text":""},{"location":"implementation.html#system-architecture-overview","title":"System Architecture Overview","text":""},{"location":"implementation.html#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Input Layer   \u2502    \u2502  Processing      \u2502    \u2502   Output Layer  \u2502\n\u2502                 \u2502    \u2502  Layer           \u2502    \u2502                 \u2502\n\u2502 \u2022 File Upload   \u2502\u2500\u2500\u2500\u25b6\u2502 \u2022 Orchestrator   \u2502\u2500\u2500\u2500\u25b6\u2502 \u2022 Results       \u2502\n\u2502 \u2022 API Gateway   \u2502    \u2502 \u2022 Text Analysis  \u2502    \u2502 \u2022 Notifications \u2502\n\u2502 \u2022 Validation    \u2502    \u2502 \u2022 Doc Analysis   \u2502    \u2502 \u2022 Storage       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                              \u2502\n                              \u25bc\n                       \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                       \u2502  External APIs  \u2502\n                       \u2502                 \u2502\n                       \u2502 \u2022 Google DocAI  \u2502\n                       \u2502 \u2022 Resistant AI  \u2502\n                       \u2502 \u2022 OpenAI        \u2502\n                       \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"implementation.html#component-responsibilities","title":"Component Responsibilities","text":""},{"location":"implementation.html#1-input-layer","title":"1. Input Layer","text":"<ul> <li>File Upload Service: Handles file uploads, validation, and storage</li> <li>API Gateway: Manages authentication, rate limiting, and routing</li> <li>Validation Service: Validates input data and file formats</li> </ul>"},{"location":"implementation.html#2-processing-layer","title":"2. Processing Layer","text":"<ul> <li>Orchestrator: Coordinates all processing flows</li> <li>Text Analysis Engine: Analyzes historical data for anomalies</li> <li>Document Analysis Engine: Processes files for tampering and content</li> <li>Scoring Engine: Generates final scores and explanations</li> </ul>"},{"location":"implementation.html#3-output-layer","title":"3. Output Layer","text":"<ul> <li>Results Service: Formats and delivers results</li> <li>Notification Service: Sends alerts and updates</li> <li>Storage Service: Manages data persistence</li> </ul>"},{"location":"implementation.html#development-environment-setup","title":"Development Environment Setup","text":""},{"location":"implementation.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Node.js 16+ (for API gateway)</li> <li>Docker and Docker Compose</li> <li>Google Cloud SDK</li> <li>OpenAI API access</li> </ul>"},{"location":"implementation.html#local-development-setup","title":"Local Development Setup","text":""},{"location":"implementation.html#1-clone-and-setup-repository","title":"1. Clone and Setup Repository","text":"<pre><code>git clone &lt;repository-url&gt;\ncd anomaly-detection-system\n</code></pre>"},{"location":"implementation.html#2-python-environment-setup","title":"2. Python Environment Setup","text":"<pre><code># Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"implementation.html#3-environment-configuration","title":"3. Environment Configuration","text":"<pre><code># Copy environment template\ncp .env.example .env\n\n# Configure environment variables\nGOOGLE_CLOUD_PROJECT=your-project-id\nGOOGLE_APPLICATION_CREDENTIALS=path/to/service-account.json\nOPENAI_API_KEY=your-openai-api-key\nRESISTANT_AI_API_KEY=your-resistant-ai-key\n</code></pre>"},{"location":"implementation.html#api-design","title":"API Design","text":""},{"location":"implementation.html#main-api-endpoints","title":"Main API Endpoints","text":""},{"location":"implementation.html#post-apiv1anomaly-detection","title":"POST /api/v1/anomaly-detection","text":"<p>Main anomaly detection endpoint that accepts: - <code>question_id</code>: String identifier for the question - <code>answer</code>: User's answer to validate - <code>files</code>: List of uploaded files - <code>metadata</code>: Optional metadata</p> <p>Returns comprehensive anomaly analysis with three scores: - Text anomaly score - Tampering score - Support score</p>"},{"location":"implementation.html#get-apiv1health","title":"GET /api/v1/health","text":"<p>Health check endpoint for monitoring system status.</p>"},{"location":"implementation.html#get-apiv1resultsrun_id","title":"GET /api/v1/results/{run_id}","text":"<p>Retrieve results by run ID for tracking processing status.</p>"},{"location":"implementation.html#database-design","title":"Database Design","text":""},{"location":"implementation.html#core-tables","title":"Core Tables","text":""},{"location":"implementation.html#processing-runs","title":"Processing Runs","text":"<p>Stores information about each anomaly detection run: - <code>run_id</code>: Unique identifier - <code>question_id</code>: Question being analyzed - <code>answer</code>: User's answer - <code>status</code>: Processing status - <code>created_at</code>: Timestamp - <code>processing_time_ms</code>: Processing duration</p>"},{"location":"implementation.html#files","title":"Files","text":"<p>Stores information about uploaded files: - <code>file_id</code>: Unique file identifier - <code>run_id</code>: Associated processing run - <code>file_path</code>: Storage path - <code>file_type</code>: File format - <code>file_size</code>: File size in bytes - <code>sha256_hash</code>: File integrity hash</p>"},{"location":"implementation.html#analysis-results","title":"Analysis Results","text":"<p>Stores the final analysis results: - <code>result_id</code>: Unique result identifier - <code>run_id</code>: Associated processing run - <code>text_anomaly_score</code>: Text analysis score - <code>tampering_score</code>: Document tampering score - <code>support_score</code>: Answer support score - <code>final_decision</code>: Overall decision</p>"},{"location":"implementation.html#deployment-strategy","title":"Deployment Strategy","text":""},{"location":"implementation.html#docker-configuration","title":"Docker Configuration","text":"<p>The system can be deployed using Docker containers with: - Main Application: FastAPI-based anomaly detection service - Database: PostgreSQL for data persistence - Cache: Redis for session management - Reverse Proxy: Nginx for load balancing</p>"},{"location":"implementation.html#environment-variables","title":"Environment Variables","text":"<p>Key environment variables for configuration: - <code>DATABASE_URL</code>: PostgreSQL connection string - <code>REDIS_URL</code>: Redis connection string - <code>GOOGLE_CLOUD_PROJECT</code>: Google Cloud project ID - <code>OPENAI_API_KEY</code>: OpenAI API key - <code>RESISTANT_AI_API_KEY</code>: Resistant AI API key</p>"},{"location":"implementation.html#testing-strategy","title":"Testing Strategy","text":""},{"location":"implementation.html#unit-tests","title":"Unit Tests","text":"<ul> <li>Test individual components in isolation</li> <li>Mock external dependencies</li> <li>Verify error handling and edge cases</li> </ul>"},{"location":"implementation.html#integration-tests","title":"Integration Tests","text":"<ul> <li>Test API endpoints with real data</li> <li>Verify database interactions</li> <li>Test file upload and processing</li> </ul>"},{"location":"implementation.html#performance-tests","title":"Performance Tests","text":"<ul> <li>Load testing with concurrent requests</li> <li>Memory and CPU usage monitoring</li> <li>Response time validation</li> </ul>"},{"location":"implementation.html#monitoring-and-logging","title":"Monitoring and Logging","text":""},{"location":"implementation.html#structured-logging","title":"Structured Logging","text":"<ul> <li>JSON-formatted logs for easy parsing</li> <li>Correlation IDs for request tracking</li> <li>Error tracking and alerting</li> </ul>"},{"location":"implementation.html#health-checks","title":"Health Checks","text":"<ul> <li>Database connectivity</li> <li>External API availability</li> <li>System resource monitoring</li> </ul>"},{"location":"implementation.html#metrics-collection","title":"Metrics Collection","text":"<ul> <li>Processing time tracking</li> <li>Error rate monitoring</li> <li>Cost per document analysis</li> </ul>"},{"location":"roadmap.html","title":"Roadmap","text":""},{"location":"roadmap.html#current-status","title":"Current Status","text":"<p>The anomaly detection system is currently in the development phase with core architecture and documentation completed. The system is designed to validate metric catalog records against supporting documents using Google Document AI and Resistant AI.</p>"},{"location":"roadmap.html#phase-1-core-implementation-q1-2025","title":"Phase 1: Core Implementation (Q1 2025)","text":""},{"location":"roadmap.html#completed","title":"\u2705 Completed","text":"<ul> <li>[x] System architecture design</li> <li>[x] Technology stack selection</li> <li>[x] API design and specifications</li> <li>[x] Database schema design</li> <li>[x] Documentation framework setup</li> </ul>"},{"location":"roadmap.html#in-progress","title":"\ud83d\udea7 In Progress","text":"<ul> <li>[ ] Core orchestrator implementation</li> <li>[ ] Google Document AI integration</li> <li>[ ] Resistant AI integration</li> <li>[ ] Basic API endpoints</li> <li>[ ] Database implementation</li> </ul>"},{"location":"roadmap.html#planned","title":"\ud83d\udccb Planned","text":"<ul> <li>[ ] Text analysis engine</li> <li>[ ] Document analysis engine</li> <li>[ ] Scoring engine</li> <li>[ ] Basic error handling</li> <li>[ ] Unit tests</li> </ul>"},{"location":"roadmap.html#phase-2-integration-testing-q2-2025","title":"Phase 2: Integration &amp; Testing (Q2 2025)","text":""},{"location":"roadmap.html#planned_1","title":"\ud83d\udccb Planned","text":"<ul> <li>[ ] End-to-end integration testing</li> <li>[ ] Performance optimization</li> <li>[ ] Security implementation</li> <li>[ ] Monitoring and logging</li> <li>[ ] Docker containerization</li> <li>[ ] CI/CD pipeline setup</li> </ul>"},{"location":"roadmap.html#integration-tasks","title":"\ud83d\udd04 Integration Tasks","text":"<ul> <li>[ ] Google Cloud setup and configuration</li> <li>[ ] Resistant AI API integration</li> <li>[ ] OpenAI API integration</li> <li>[ ] Database deployment</li> <li>[ ] File storage implementation</li> </ul>"},{"location":"roadmap.html#testing-strategy","title":"\ud83e\uddea Testing Strategy","text":"<ul> <li>[ ] Unit test coverage (&gt;80%)</li> <li>[ ] Integration test suite</li> <li>[ ] Performance testing</li> <li>[ ] Security testing</li> <li>[ ] Load testing</li> <li>[ ] User acceptance testing</li> </ul>"},{"location":"roadmap.html#phase-3-deployment-launch-q3-2025","title":"Phase 3: Deployment &amp; Launch (Q3 2025)","text":""},{"location":"roadmap.html#deployment","title":"\ud83d\ude80 Deployment","text":"<ul> <li>[ ] Production environment setup</li> <li>[ ] Database migration scripts</li> <li>[ ] Environment configuration</li> <li>[ ] SSL/TLS certificates</li> <li>[ ] Domain configuration</li> <li>[ ] CDN setup</li> </ul>"},{"location":"roadmap.html#monitoring","title":"\ud83d\udcca Monitoring","text":"<ul> <li>[ ] Application monitoring (Prometheus/Grafana)</li> <li>[ ] Log aggregation (ELK stack)</li> <li>[ ] Error tracking (Sentry)</li> <li>[ ] Performance monitoring</li> <li>[ ] Cost monitoring</li> <li>[ ] Alert configuration</li> </ul>"},{"location":"roadmap.html#security","title":"\ud83d\udd12 Security","text":"<ul> <li>[ ] Authentication and authorization</li> <li>[ ] API rate limiting</li> <li>[ ] Input validation</li> <li>[ ] Data encryption</li> <li>[ ] Security headers</li> <li>[ ] Vulnerability scanning</li> </ul>"},{"location":"roadmap.html#phase-4-enhancement-scale-q4-2025","title":"Phase 4: Enhancement &amp; Scale (Q4 2025)","text":""},{"location":"roadmap.html#feature-enhancements","title":"\ud83c\udfaf Feature Enhancements","text":"<ul> <li>[ ] Advanced scoring algorithms</li> <li>[ ] Custom processor support</li> <li>[ ] Batch processing capabilities</li> <li>[ ] Real-time processing</li> <li>[ ] Mobile API support</li> <li>[ ] Webhook notifications</li> </ul>"},{"location":"roadmap.html#scalability","title":"\ud83d\udcc8 Scalability","text":"<ul> <li>[ ] Horizontal scaling</li> <li>[ ] Load balancing</li> <li>[ ] Database optimization</li> <li>[ ] Caching implementation</li> <li>[ ] CDN optimization</li> <li>[ ] Auto-scaling configuration</li> </ul>"},{"location":"roadmap.html#advanced-features","title":"\ud83d\udd27 Advanced Features","text":"<ul> <li>[ ] Machine learning model training</li> <li>[ ] Custom document types</li> <li>[ ] Advanced analytics</li> <li>[ ] Reporting dashboard</li> <li>[ ] API versioning</li> <li>[ ] GraphQL support</li> </ul>"},{"location":"roadmap.html#phase-5-enterprise-features-q1-2026","title":"Phase 5: Enterprise Features (Q1 2026)","text":""},{"location":"roadmap.html#enterprise-capabilities","title":"\ud83c\udfe2 Enterprise Capabilities","text":"<ul> <li>[ ] Multi-tenant support</li> <li>[ ] Role-based access control</li> <li>[ ] Audit logging</li> <li>[ ] Compliance reporting</li> <li>[ ] Data retention policies</li> <li>[ ] Backup and recovery</li> </ul>"},{"location":"roadmap.html#integrations","title":"\ud83d\udd17 Integrations","text":"<ul> <li>[ ] Third-party API integrations</li> <li>[ ] Webhook system</li> <li>[ ] Event streaming</li> <li>[ ] Message queues</li> <li>[ ] External database connections</li> <li>[ ] File system integrations</li> </ul>"},{"location":"roadmap.html#analytics-reporting","title":"\ud83d\udcca Analytics &amp; Reporting","text":"<ul> <li>[ ] Business intelligence dashboard</li> <li>[ ] Custom reports</li> <li>[ ] Data export capabilities</li> <li>[ ] Trend analysis</li> <li>[ ] Performance metrics</li> <li>[ ] Cost analysis tools</li> </ul>"},{"location":"roadmap.html#technical-debt-maintenance","title":"Technical Debt &amp; Maintenance","text":""},{"location":"roadmap.html#code-quality","title":"\ud83d\udd27 Code Quality","text":"<ul> <li>[ ] Code review process</li> <li>[ ] Static analysis tools</li> <li>[ ] Code coverage monitoring</li> <li>[ ] Documentation updates</li> <li>[ ] Refactoring tasks</li> <li>[ ] Performance optimization</li> </ul>"},{"location":"roadmap.html#infrastructure","title":"\ud83d\udee0\ufe0f Infrastructure","text":"<ul> <li>[ ] Infrastructure as Code</li> <li>[ ] Automated backups</li> <li>[ ] Disaster recovery</li> <li>[ ] Security updates</li> <li>[ ] Dependency updates</li> <li>[ ] Environment parity</li> </ul>"},{"location":"roadmap.html#research-development","title":"Research &amp; Development","text":""},{"location":"roadmap.html#rd-projects","title":"\ud83d\udd2c R&amp;D Projects","text":"<ul> <li>[ ] Custom ML models for document analysis</li> <li>[ ] Advanced tampering detection</li> <li>[ ] Natural language processing improvements</li> <li>[ ] Computer vision enhancements</li> <li>[ ] Blockchain integration</li> <li>[ ] Edge computing support</li> </ul>"},{"location":"roadmap.html#learning-development","title":"\ud83d\udcda Learning &amp; Development","text":"<ul> <li>[ ] Team training programs</li> <li>[ ] Technology workshops</li> <li>[ ] Conference attendance</li> <li>[ ] Open source contributions</li> <li>[ ] Research publications</li> <li>[ ] Patent applications</li> </ul>"},{"location":"roadmap.html#community-open-source","title":"Community &amp; Open Source","text":""},{"location":"roadmap.html#community-building","title":"\ud83c\udf10 Community Building","text":"<ul> <li>[ ] Open source project launch</li> <li>[ ] Contributor guidelines</li> <li>[ ] Documentation for contributors</li> <li>[ ] Issue templates</li> <li>[ ] Pull request templates</li> <li>[ ] Community forums</li> </ul>"},{"location":"roadmap.html#documentation","title":"\ud83d\udcd6 Documentation","text":"<ul> <li>[ ] API documentation</li> <li>[ ] Developer guides</li> <li>[ ] User manuals</li> <li>[ ] Video tutorials</li> <li>[ ] Blog posts</li> <li>[ ] Case studies</li> </ul>"},{"location":"roadmap.html#success-metrics","title":"Success Metrics","text":""},{"location":"roadmap.html#key-performance-indicators","title":"\ud83d\udcca Key Performance Indicators","text":"<ul> <li>Processing Accuracy: &gt;95% accuracy in anomaly detection</li> <li>Processing Speed: &lt;30 seconds per document analysis</li> <li>System Uptime: &gt;99.9% availability</li> <li>Cost Efficiency: &lt;$0.10 per document analysis</li> <li>User Satisfaction: &gt;4.5/5 rating</li> <li>API Response Time: &lt;2 seconds for 95% of requests</li> </ul>"},{"location":"roadmap.html#business-goals","title":"\ud83c\udfaf Business Goals","text":"<ul> <li>Market Adoption: 100+ active users by end of 2025</li> <li>Revenue Growth: $100K+ ARR by end of 2025</li> <li>Partnerships: 5+ strategic partnerships</li> <li>Awards: Industry recognition for innovation</li> <li>Team Growth: 10+ team members by end of 2025</li> </ul>"},{"location":"roadmap.html#risk-management","title":"Risk Management","text":""},{"location":"roadmap.html#technical-risks","title":"\u26a0\ufe0f Technical Risks","text":"<ul> <li>API Dependencies: Mitigate with fallback options</li> <li>Scalability Issues: Plan for horizontal scaling</li> <li>Data Security: Implement comprehensive security measures</li> <li>Performance Degradation: Monitor and optimize continuously</li> <li>Integration Failures: Implement robust error handling</li> </ul>"},{"location":"roadmap.html#business-risks","title":"\ud83d\udcbc Business Risks","text":"<ul> <li>Market Competition: Focus on unique value proposition</li> <li>Regulatory Changes: Stay updated with compliance requirements</li> <li>Technology Changes: Adapt to new technologies and standards</li> <li>Team Attrition: Implement knowledge sharing and documentation</li> <li>Funding: Secure additional funding if needed</li> </ul>"},{"location":"roadmap.html#feedback-iteration","title":"Feedback &amp; Iteration","text":""},{"location":"roadmap.html#feedback-collection","title":"\ud83d\udcdd Feedback Collection","text":"<ul> <li>[ ] User feedback system</li> <li>[ ] Beta testing program</li> <li>[ ] Customer interviews</li> <li>[ ] Usage analytics</li> <li>[ ] Performance monitoring</li> <li>[ ] Error tracking</li> </ul>"},{"location":"roadmap.html#continuous-improvement","title":"\ud83d\udd04 Continuous Improvement","text":"<ul> <li>[ ] Monthly retrospectives</li> <li>[ ] Quarterly planning sessions</li> <li>[ ] Annual strategy reviews</li> <li>[ ] Technology assessments</li> <li>[ ] Market research</li> <li>[ ] Competitive analysis</li> </ul>"},{"location":"roadmap.html#conclusion","title":"Conclusion","text":"<p>This roadmap provides a comprehensive plan for developing, deploying, and scaling the anomaly detection system. The phased approach ensures steady progress while maintaining quality and addressing technical and business challenges. Regular reviews and updates will ensure the roadmap remains relevant and achievable.</p> <p>For questions or suggestions about this roadmap, please contact the development team or create an issue in the project repository.</p>"},{"location":"sample.html","title":"Sample Usage","text":""},{"location":"sample.html#overview","title":"Overview","text":"<p>This section provides practical examples of how to use the anomaly detection system, including API calls, response formats, and common use cases.</p>"},{"location":"sample.html#api-examples","title":"API Examples","text":""},{"location":"sample.html#basic-anomaly-detection-request","title":"Basic Anomaly Detection Request","text":""},{"location":"sample.html#request","title":"Request","text":"<pre><code>curl -X POST \"https://api.anomaly-detection.com/v1/anomaly-detection\" \\\n  -H \"Content-Type: multipart/form-data\" \\\n  -F \"question_id=q_001\" \\\n  -F \"answer=7832.67\" \\\n  -F \"files=@utility_bill_april.pdf\" \\\n  -F \"files=@utility_bill_may.pdf\" \\\n  -F \"files=@utility_bill_june.pdf\"\n</code></pre>"},{"location":"sample.html#response","title":"Response","text":"<pre><code>{\n  \"run_id\": \"run_12345\",\n  \"question_id\": \"q_001\",\n  \"timestamp\": \"2025-01-15T10:30:00Z\",\n  \"processing_time_ms\": 2500,\n  \"text_anomaly\": {\n    \"score\": 22.0,\n    \"label\": \"normal\",\n    \"explanation\": \"Answer falls within expected range based on historical data\",\n    \"confidence\": 0.85\n  },\n  \"tampering\": {\n    \"aggregate_score\": 15.0,\n    \"label\": \"clean\",\n    \"explanation\": \"No forensic anomalies detected; digital signatures valid\",\n    \"files\": [\n      {\n        \"file_id\": \"f_001\",\n        \"score\": 15.0,\n        \"decision\": \"clean\",\n        \"indicators\": [],\n        \"confidence\": 0.92\n      }\n    ]\n  },\n  \"support\": {\n    \"coverage\": 1.0,\n    \"score\": 84.0,\n    \"label\": \"strongly_supported\",\n    \"explanation\": \"Sum(Apr\u2013Jun)=7,833 kWh; within 0.02% of submitted 7,832.67 after rounding\",\n    \"citations\": [\n      {\n        \"file_id\": \"f_001\",\n        \"page\": 1,\n        \"span\": \"Usage history Apr\u2013Jun 2025\",\n        \"extracted_value\": 7833,\n        \"confidence\": 0.93\n      }\n    ]\n  },\n  \"final_decision\": \"validated\"\n}\n</code></pre>"},{"location":"sample.html#use-cases","title":"Use Cases","text":""},{"location":"sample.html#1-esg-reporting-validation","title":"1. ESG Reporting Validation","text":"<p>A company needs to validate their carbon footprint data for ESG reporting.</p>"},{"location":"sample.html#2-financial-document-verification","title":"2. Financial Document Verification","text":"<p>A bank needs to verify income statements for loan applications.</p>"},{"location":"sample.html#3-compliance-auditing","title":"3. Compliance Auditing","text":"<p>An auditor needs to verify expense claims for tax purposes.</p>"},{"location":"sample.html#integration-examples","title":"Integration Examples","text":""},{"location":"sample.html#python-sdk-usage","title":"Python SDK Usage","text":"<pre><code>from anomaly_detection import AnomalyDetectionClient\n\n# Initialize client\nclient = AnomalyDetectionClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://api.anomaly-detection.com\"\n)\n\n# Analyze documents\nresult = client.analyze(\n    question_id=\"electricity_consumption_q3_2025\",\n    answer=\"7832.67\",\n    files=[\"april_bill.pdf\", \"may_bill.pdf\", \"june_bill.pdf\"]\n)\n\n# Check results\nif result.final_decision == \"validated\":\n    print(\"\u2705 Document validation successful\")\nelse:\n    print(\"\u274c Document validation failed\")\n</code></pre>"},{"location":"sample.html#best-practices","title":"Best Practices","text":""},{"location":"sample.html#1-file-preparation","title":"1. File Preparation","text":"<ul> <li>Use PDF format when possible for best results</li> <li>Ensure documents are clear and readable</li> <li>Keep files under 10MB for optimal processing</li> </ul>"},{"location":"sample.html#2-answer-formatting","title":"2. Answer Formatting","text":"<ul> <li>Include appropriate decimal places</li> <li>Specify units clearly (kWh, $, etc.)</li> <li>Use consistent formatting across submissions</li> </ul>"},{"location":"sample.html#3-error-handling","title":"3. Error Handling","text":"<ul> <li>Implement retry logic for transient failures</li> <li>Set appropriate timeouts for API calls</li> <li>Have fallback validation methods</li> </ul>"},{"location":"scoring.html","title":"Scoring &amp; Final Output","text":""},{"location":"scoring.html#overview","title":"Overview","text":"<p>The anomaly detection system produces three comprehensive scores that evaluate different aspects of document validation and answer consistency. Each score includes detailed explanations and confidence measures to provide transparent, auditable results.</p>"},{"location":"scoring.html#scoring-components","title":"Scoring Components","text":""},{"location":"scoring.html#1-text-anomaly-score","title":"1. Text Anomaly Score","text":"<p>Purpose: Evaluate the consistency of the provided answer against historical data for the same question.</p> <p>Range: 0-100 (higher = more anomalous)</p> <p>Calculation Method: - Statistical analysis of historical answers (mean, standard deviation, outliers) - Pattern recognition and semantic similarity analysis - Weighted combination of statistical and pattern-based scores</p> <p>Labels: - Normal (0-30): Answer falls within expected range - Suspicious (30-60): Answer shows some deviation from historical patterns - Anomalous (60-100): Answer significantly deviates from historical data</p>"},{"location":"scoring.html#2-tampering-score","title":"2. Tampering Score","text":"<p>Purpose: Assess the likelihood that attached documents have been manipulated or tampered with.</p> <p>Range: 0-100 (higher = more likely tampered)</p> <p>Calculation Method: - Forensic analysis using Resistant AI - Detection of digital manipulation indicators - Analysis of document structure, metadata, and content consistency - Aggregation across multiple files</p> <p>Labels: - Clean (0-30): No forensic anomalies detected - Suspicious (30-60): Some indicators of potential tampering - Likely Tampered (60-100): Strong evidence of document manipulation</p>"},{"location":"scoring.html#3-support-score","title":"3. Support Score","text":"<p>Purpose: Evaluate how well the extracted document content supports the provided answer.</p> <p>Range: 0-100 (higher = better supported)</p> <p>Calculation Method: - Content extraction and normalization - Comparison of extracted data with provided answer - Coverage analysis (completeness of evidence) - Tolerance-based validation (\u00b12% or \u00b150 kWh for electricity)</p> <p>Labels: - Not Supported (0-30): Evidence contradicts the answer - Weak Support (30-60): Limited evidence supporting the answer - Supported (60-80): Good evidence supporting the answer - Strongly Supported (80-100): Strong evidence supporting the answer</p>"},{"location":"scoring.html#final-output-format","title":"Final Output Format","text":""},{"location":"scoring.html#complete-response-structure","title":"Complete Response Structure","text":"<pre><code>{\n  \"run_id\": \"run_12345\",\n  \"question_id\": \"q_001\",\n  \"timestamp\": \"2025-01-15T10:30:00Z\",\n  \"processing_time_ms\": 2500,\n  \"text_anomaly\": {\n    \"score\": 22.0,\n    \"label\": \"normal\",\n    \"explanation\": \"Answer falls within expected range based on historical data\",\n    \"confidence\": 0.85,\n    \"statistical_analysis\": {\n      \"mean_length\": 150,\n      \"std_length\": 25,\n      \"z_score\": 0.8,\n      \"percentile\": 75\n    },\n    \"pattern_analysis\": {\n      \"semantic_similarity\": 0.82,\n      \"vocab_overlap\": 0.75,\n      \"sentiment_deviation\": 0.1\n    }\n  },\n  \"tampering\": {\n    \"aggregate_score\": 15.0,\n    \"label\": \"clean\",\n    \"explanation\": \"No forensic anomalies detected; digital signatures valid\",\n    \"files\": [\n      {\n        \"file_id\": \"f_001\",\n        \"score\": 15.0,\n        \"decision\": \"clean\",\n        \"indicators\": [],\n        \"confidence\": 0.92\n      }\n    ]\n  },\n  \"support\": {\n    \"coverage\": 1.0,\n    \"score\": 84.0,\n    \"label\": \"strongly_supported\",\n    \"explanation\": \"Sum(Apr\u2013Jun)=7,833 kWh; within 0.02% of submitted 7,832.67 after rounding\",\n    \"citations\": [\n      {\n        \"file_id\": \"f_001\",\n        \"page\": 1,\n        \"span\": \"Usage history Apr\u2013Jun 2025\",\n        \"extracted_value\": 7833,\n        \"confidence\": 0.93\n      }\n    ]\n  },\n  \"final_decision\": \"validated\",\n  \"quality_metrics\": {\n    \"overall_confidence\": 0.87,\n    \"data_completeness\": 1.0,\n    \"processing_quality\": \"high\"\n  }\n}\n</code></pre>"},{"location":"scoring.html#score-aggregation-logic","title":"Score Aggregation Logic","text":""},{"location":"scoring.html#final-decision-rules","title":"Final Decision Rules","text":"<p>The system combines all three scores to determine the final decision:</p> <pre><code>def determine_final_decision(text_anomaly, tampering, support):\n    \"\"\"Determine final decision based on all scores\"\"\"\n\n    # Rule 1: High tampering score overrides everything\n    if tampering.score &gt; 60:\n        return \"not_validated\"\n\n    # Rule 2: Low support score indicates insufficient evidence\n    if support.score &lt; 30:\n        return \"not_supported\"\n\n    # Rule 3: High text anomaly with low support\n    if text_anomaly.score &gt; 60 and support.score &lt; 60:\n        return \"suspicious\"\n\n    # Rule 4: Good scores across all dimensions\n    if (text_anomaly.score &lt; 30 and \n        tampering.score &lt; 30 and \n        support.score &gt; 80):\n        return \"validated\"\n\n    # Rule 5: Moderate scores\n    if (text_anomaly.score &lt; 60 and \n        tampering.score &lt; 60 and \n        support.score &gt; 60):\n        return \"conditionally_validated\"\n\n    # Default: Requires review\n    return \"requires_review\"\n</code></pre>"},{"location":"scoring.html#quality-metrics","title":"Quality Metrics","text":"<p>The system also provides overall quality metrics:</p> <ul> <li>Overall Confidence: Weighted average of all confidence scores</li> <li>Data Completeness: Percentage of required data successfully extracted</li> <li>Processing Quality: Assessment of processing success and reliability</li> </ul>"},{"location":"scoring.html#explanation-generation","title":"Explanation Generation","text":""},{"location":"scoring.html#text-anomaly-explanations","title":"Text Anomaly Explanations","text":"<pre><code>def generate_text_explanation(score, stats, patterns):\n    \"\"\"Generate human-readable explanation for text anomaly score\"\"\"\n\n    if score &lt; 30:\n        return \"Answer falls within expected range based on historical data\"\n    elif score &lt; 60:\n        return f\"Answer shows moderate deviation from historical patterns (z-score: {stats.z_score:.2f})\"\n    else:\n        return f\"Answer significantly deviates from historical data (percentile: {stats.percentile:.1f}%)\"\n</code></pre>"},{"location":"scoring.html#tampering-explanations","title":"Tampering Explanations","text":"<pre><code>def generate_tampering_explanation(score, indicators):\n    \"\"\"Generate explanation for tampering score\"\"\"\n\n    if score &lt; 30:\n        return \"No forensic anomalies detected; digital signatures valid\"\n    elif score &lt; 60:\n        return f\"Some indicators of potential tampering: {', '.join(indicators[:2])}\"\n    else:\n        return f\"Strong evidence of document manipulation: {', '.join(indicators)}\"\n</code></pre>"},{"location":"scoring.html#support-explanations","title":"Support Explanations","text":"<pre><code>def generate_support_explanation(score, citations, coverage):\n    \"\"\"Generate explanation for support score\"\"\"\n\n    if score &gt; 80:\n        return f\"Strong evidence supporting the answer with {coverage:.1%} coverage\"\n    elif score &gt; 60:\n        return f\"Good evidence supporting the answer with {coverage:.1%} coverage\"\n    elif score &gt; 30:\n        return f\"Limited evidence supporting the answer with {coverage:.1%} coverage\"\n    else:\n        return \"Insufficient evidence to support the answer\"\n</code></pre>"},{"location":"scoring.html#confidence-scoring","title":"Confidence Scoring","text":""},{"location":"scoring.html#confidence-calculation","title":"Confidence Calculation","text":"<p>Each score includes a confidence measure based on:</p> <ul> <li>Data Quality: Completeness and reliability of input data</li> <li>Processing Success: Success rate of analysis components</li> <li>Model Confidence: Confidence from machine learning models</li> <li>Historical Performance: Accuracy of similar analyses</li> </ul>"},{"location":"scoring.html#confidence-thresholds","title":"Confidence Thresholds","text":"<ul> <li>High Confidence: &gt; 0.8</li> <li>Medium Confidence: 0.5 - 0.8</li> <li>Low Confidence: &lt; 0.5</li> </ul>"},{"location":"scoring.html#audit-trail","title":"Audit Trail","text":""},{"location":"scoring.html#processing-log","title":"Processing Log","text":"<p>Every analysis includes a detailed audit trail:</p> <pre><code>{\n  \"audit_trail\": {\n    \"processing_steps\": [\n      {\n        \"step\": \"file_validation\",\n        \"timestamp\": \"2025-01-15T10:30:00Z\",\n        \"status\": \"success\",\n        \"details\": \"3 files validated successfully\"\n      },\n      {\n        \"step\": \"tampering_detection\",\n        \"timestamp\": \"2025-01-15T10:30:15Z\",\n        \"status\": \"success\",\n        \"details\": \"Resistant AI analysis completed\"\n      },\n      {\n        \"step\": \"content_extraction\",\n        \"timestamp\": \"2025-01-15T10:30:30Z\",\n        \"status\": \"success\",\n        \"details\": \"Document AI extraction completed\"\n      }\n    ],\n    \"api_calls\": [\n      {\n        \"service\": \"resistant_ai\",\n        \"endpoint\": \"/analyze\",\n        \"response_time_ms\": 1200,\n        \"status_code\": 200\n      }\n    ],\n    \"cost_breakdown\": {\n      \"document_ai\": 0.09,\n      \"resistant_ai\": 0.50,\n      \"llm\": 0.002,\n      \"total\": 0.592\n    }\n  }\n}\n</code></pre>"},{"location":"scoring.html#quality-assurance","title":"Quality Assurance","text":""},{"location":"scoring.html#validation-checks","title":"Validation Checks","text":"<ul> <li>Score Consistency: Verify scores are within expected ranges</li> <li>Explanation Quality: Ensure explanations are clear and accurate</li> <li>Data Integrity: Validate all extracted data and citations</li> <li>Processing Completeness: Confirm all required steps completed</li> </ul>"},{"location":"scoring.html#human-review-triggers","title":"Human Review Triggers","text":"<ul> <li>Low Confidence: Scores with confidence &lt; 0.5</li> <li>High Anomaly: Text anomaly score &gt; 80</li> <li>Tampering Detected: Tampering score &gt; 60</li> <li>Insufficient Support: Support score &lt; 30</li> <li>Processing Errors: Any component failures</li> </ul>"},{"location":"scoring.html#performance-metrics","title":"Performance Metrics","text":""},{"location":"scoring.html#key-performance-indicators","title":"Key Performance Indicators","text":"<ul> <li>Processing Time: Average time per analysis</li> <li>Accuracy Rate: Comparison with human review</li> <li>False Positive Rate: Incorrect anomaly detections</li> <li>False Negative Rate: Missed anomalies</li> <li>Cost per Analysis: Total cost per document</li> </ul>"},{"location":"scoring.html#monitoring-and-alerting","title":"Monitoring and Alerting","text":"<ul> <li>Score Distribution: Monitor score distributions for anomalies</li> <li>Processing Delays: Alert when processing time exceeds SLA</li> <li>Error Rates: Alert when error rates increase</li> <li>Cost Thresholds: Alert when costs exceed budget</li> </ul>"},{"location":"scoring.html#future-enhancements","title":"Future Enhancements","text":""},{"location":"scoring.html#advanced-scoring","title":"Advanced Scoring","text":"<ul> <li>Machine Learning Models: Train custom models for specific domains</li> <li>Ensemble Methods: Combine multiple scoring approaches</li> <li>Adaptive Thresholds: Adjust thresholds based on historical performance</li> <li>Real-time Learning: Update models with new data</li> </ul>"},{"location":"scoring.html#enhanced-explanations","title":"Enhanced Explanations","text":"<ul> <li>Natural Language Generation: Generate more natural explanations</li> <li>Visual Explanations: Include charts and graphs</li> <li>Interactive Explanations: Allow users to explore details</li> <li>Multilingual Support: Support multiple languages</li> </ul>"},{"location":"technology-stack.html","title":"Technology Stack","text":""},{"location":"technology-stack.html#google-document-ai-resistant-ai-integration","title":"Google Document AI + Resistant AI Integration","text":"<p>This guide provides detailed implementation instructions for integrating Google Document AI and Resistant AI into your anomaly detection system. The combination of these two services provides:</p> <ul> <li>Google Document AI: High-accuracy content extraction from various document formats</li> <li>Resistant AI: Forensic-grade document tampering detection</li> <li>Seamless Integration: Both services work together through Google Cloud Marketplace</li> </ul>"},{"location":"technology-stack.html#why-this-combination","title":"Why This Combination?","text":"<p>Google officially recommends using Resistant AI with Document AI for enhanced fraud detection. This combination provides:</p> <ol> <li>Comprehensive Coverage: Document AI extracts content, Resistant AI detects tampering</li> <li>Enterprise Integration: Both available through Google Cloud Marketplace</li> <li>Scalable Pricing: Pay-per-use model with volume discounts</li> <li>High Accuracy: Specialized processors for different document types</li> </ol>"},{"location":"technology-stack.html#google-document-ai-setup","title":"Google Document AI Setup","text":""},{"location":"technology-stack.html#available-processors","title":"Available Processors","text":"Processor Purpose Cost Best For Form Parser General extraction $30/1,000 pages Most documents Utility Parser Utility bills $0.10 per 10 pages Utility bills Layout Parser Text and tables $10/1,000 pages Structured documents Enterprise OCR High-accuracy OCR $1.50/1,000 pages Image-only documents"},{"location":"technology-stack.html#processor-selection-logic","title":"Processor Selection Logic","text":"<pre><code>class ProcessorSelector:\n    def __init__(self, project_id: str, location: str):\n        self.project_id = project_id\n        self.location = location\n\n    def select_processor(self, file_info: FileInfo) -&gt; str:\n        \"\"\"Select appropriate processor based on file characteristics\"\"\"\n\n        # Check file type\n        if file_info.file_type.lower() in ['utility_bill', 'electricity_bill', 'gas_bill']:\n            return 'utility_parser'\n\n        # Check if it's an image-only document\n        if file_info.file_type.lower() in ['jpg', 'jpeg', 'png', 'tiff']:\n            return 'enterprise_ocr'\n\n        # Default to form parser\n        return 'form_parser'\n</code></pre>"},{"location":"technology-stack.html#resistant-ai-setup","title":"Resistant AI Setup","text":""},{"location":"technology-stack.html#marketplace-integration","title":"Marketplace Integration","text":"<p>Resistant AI is available through Google Cloud Marketplace and provides:</p> <ul> <li>Document Forensics: Forensic-grade tampering detection</li> <li>Support for Multiple File Formats: PDFs, images, Office documents</li> <li>Real-time Analysis: &lt;20 seconds processing time</li> <li>Detailed Tampering Indicators: Specific evidence of manipulation</li> </ul>"},{"location":"technology-stack.html#integration-architecture","title":"Integration Architecture","text":"<p>The system uses a clean separation of concerns:</p> <ul> <li>Resistant AI = \"Is this document authentic/unaltered?\"</li> <li>Document AI = \"What does this document say?\"</li> <li>Our Agents = \"Does what it says support the user's answer?\"</li> </ul>"},{"location":"technology-stack.html#api-integration-details","title":"API Integration Details","text":""},{"location":"technology-stack.html#resistant-ai-response-format","title":"Resistant AI Response Format","text":"<pre><code>{\n  \"file_id\": \"f_001\",\n  \"tamper_score\": 78.4,\n  \"decision\": \"likely_tampered\",\n  \"indicators\": [\n    \"handwritten overlay in numeric cell\",\n    \"texture mismatch vs surrounding digits\",\n    \"incremental edit artifacts\"\n  ]\n}\n</code></pre>"},{"location":"technology-stack.html#google-document-ai-response-format","title":"Google Document AI Response Format","text":"<pre><code>{\n  \"file_id\": \"f_001\",\n  \"pages\": [\n    {\n      \"page\": 1,\n      \"kv\": [\n        {\n          \"key\": \"Usage (kWh)\",\n          \"value\": \"7833\",\n          \"bbox\": [x1, y1, x2, y2],\n          \"confidence\": 0.93\n        }\n      ],\n      \"tables\": [\n        {\n          \"name\": \"Usage history\",\n          \"rows\": [\n            {\"month\": \"Apr 2025\", \"kwh\": \"2410\"},\n            {\"month\": \"May 2025\", \"kwh\": \"2613\"},\n            {\"month\": \"Jun 2025\", \"kwh\": \"2810\"}\n          ],\n          \"bbox\": [x1, y1, x2, y2],\n          \"confidence\": 0.91\n        }\n      ],\n      \"text\": \"extracted text content\"\n    }\n  ]\n}\n</code></pre>"},{"location":"technology-stack.html#cost-optimization","title":"Cost Optimization","text":""},{"location":"technology-stack.html#processor-selection-strategy","title":"Processor Selection Strategy","text":"<ol> <li>Use Form Parser by default: Most cost-effective for general documents</li> <li>Apply for Utility Parser access: Reduces cost by ~66% for eligible documents</li> <li>Optimize page counts: Avoid unnecessary multi-page scans</li> <li>Cache common prompts: Reduce LLM costs through prompt optimization</li> <li>Storage tiering: Move older data to cheaper storage tiers</li> </ol>"},{"location":"technology-stack.html#cost-examples","title":"Cost Examples","text":"<p>Per Document (1-page utility bill): - Form Parser path: ~$0.031 + Resistant AI cost - Utility Parser path: ~$0.101 + Resistant AI cost - LLM costs: ~$0.001\u20130.002 per document - Storage: ~$0.00002\u20130.00005 per month</p> <p>Monthly Examples: - 1,000 docs: ~$95 + Resistant AI - 10,000 docs: ~$950 + Resistant AI - 100,000 docs: ~$9,500 + Resistant AI</p>"},{"location":"technology-stack.html#best-practices","title":"Best Practices","text":""},{"location":"technology-stack.html#performance-optimization","title":"Performance Optimization","text":"<ol> <li>Parallel processing: Process multiple files simultaneously</li> <li>Caching: Cache common document types and patterns</li> <li>Batch processing: Group similar documents for efficiency</li> <li>Resource management: Monitor and optimize API usage</li> </ol>"},{"location":"technology-stack.html#security-considerations","title":"Security Considerations","text":"<ol> <li>Data encryption: Encrypt files in transit and at rest</li> <li>Access controls: Implement proper authentication and authorization</li> <li>Audit trails: Log all processing steps for compliance</li> <li>Data retention: Implement proper data lifecycle management</li> </ol>"},{"location":"technology-stack.html#quality-assurance","title":"Quality Assurance","text":"<ol> <li>Confidence thresholds: Set minimum confidence levels for decisions</li> <li>Human review: Escalate uncertain cases for manual review</li> <li>Continuous monitoring: Track accuracy and performance metrics</li> <li>Feedback loops: Use results to improve algorithms</li> </ol>"},{"location":"flows/document-analysis.html","title":"Document Analysis Flow","text":"<p>Goal: Validate document authenticity and consistency; flag anomalies.</p> <p>Inputs: PDFs/images; Outputs: extracted fields, tamper indicators, support evidence.</p>"},{"location":"flows/document-analysis.html#overview","title":"Overview","text":"<p>The Document Analysis Flow processes attached files to detect tampering and extract relevant information. This flow combines Google Document AI for content extraction and Resistant AI for tampering detection to provide comprehensive document validation.</p>"},{"location":"flows/document-analysis.html#components","title":"Components","text":""},{"location":"flows/document-analysis.html#1-file-format-detection","title":"1. File Format Detection","text":"<ul> <li>Purpose: Identify file type and validate format</li> <li>Supported Formats: PDF, DOC, DOCX, XLSX, images (JPG, PNG, TIFF)</li> <li>Validation: MIME type checking, file signature verification</li> <li>Output: File type classification with confidence</li> </ul>"},{"location":"flows/document-analysis.html#2-tampering-detection-engine","title":"2. Tampering Detection Engine","text":"<ul> <li>Purpose: Detect document manipulation and fraud</li> <li>Technology: Resistant AI integration</li> <li>Analysis: Forensic examination of document structure, metadata, and content</li> <li>Output: Tampering score with detailed indicators</li> </ul>"},{"location":"flows/document-analysis.html#3-content-extraction-engine","title":"3. Content Extraction Engine","text":"<ul> <li>Purpose: Extract structured data from documents</li> <li>Technology: Google Document AI</li> <li>Processors: Form Parser, Utility Parser, Layout Parser, Enterprise OCR</li> <li>Output: Structured data with confidence scores</li> </ul>"},{"location":"flows/document-analysis.html#4-multi-file-correlation","title":"4. Multi-file Correlation","text":"<ul> <li>Purpose: Correlate information across multiple files</li> <li>Analysis: Cross-reference data, detect inconsistencies</li> <li>Validation: Verify data consistency and completeness</li> <li>Output: Correlation analysis with conflict detection</li> </ul>"},{"location":"flows/document-analysis.html#process-flow","title":"Process Flow","text":""},{"location":"flows/document-analysis.html#step-1-file-processing","title":"Step 1: File Processing","text":"<pre><code>async def process_files(self, files: List[FileInfo]) -&gt; List[ProcessingResult]:\n    \"\"\"Process multiple files in parallel\"\"\"\n\n    results = []\n    for file_info in files:\n        # Validate file format\n        validation_result = await self.validate_file(file_info)\n\n        # Process file\n        if validation_result.is_valid:\n            result = await self.process_single_file(file_info)\n            results.append(result)\n        else:\n            results.append(ProcessingResult(\n                file_id=file_info.file_id,\n                status=\"invalid\",\n                error=validation_result.error\n            ))\n\n    return results\n</code></pre>"},{"location":"flows/document-analysis.html#step-2-tampering-detection","title":"Step 2: Tampering Detection","text":"<pre><code>async def detect_tampering(self, file_info: FileInfo) -&gt; TamperingResult:\n    \"\"\"Detect tampering using Resistant AI\"\"\"\n\n    try:\n        # Call Resistant AI API\n        response = await self.resistant_ai_client.analyze_document(\n            file_path=file_info.file_path,\n            file_type=file_info.file_type\n        )\n\n        return TamperingResult(\n            file_id=file_info.file_id,\n            score=response.tamper_score,\n            decision=response.decision,\n            indicators=response.indicators,\n            confidence=response.confidence\n        )\n\n    except Exception as e:\n        logger.error(f\"Tampering detection failed for {file_info.file_id}: {str(e)}\")\n        return TamperingResult(\n            file_id=file_info.file_id,\n            score=0.0,\n            decision=\"error\",\n            indicators=[\"Processing error occurred\"],\n            confidence=0.0\n        )\n</code></pre>"},{"location":"flows/document-analysis.html#step-3-content-extraction","title":"Step 3: Content Extraction","text":"<pre><code>async def extract_content(self, file_info: FileInfo) -&gt; ContentExtractionResult:\n    \"\"\"Extract content using Google Document AI\"\"\"\n\n    try:\n        # Select appropriate processor\n        processor = self._select_processor(file_info.file_type)\n\n        # Extract content\n        extraction_result = await self.docai_client.process_document(\n            file_path=file_info.file_path,\n            processor=processor\n        )\n\n        return ContentExtractionResult(\n            file_id=file_info.file_id,\n            pages=extraction_result.pages,\n            confidence=extraction_result.confidence,\n            extracted_data=self._normalize_data(extraction_result)\n        )\n\n    except Exception as e:\n        logger.error(f\"Content extraction failed for {file_info.file_id}: {str(e)}\")\n        raise ContentExtractionError(f\"Extraction failed: {str(e)}\")\n</code></pre>"},{"location":"flows/document-analysis.html#step-4-multi-file-correlation","title":"Step 4: Multi-file Correlation","text":"<pre><code>def correlate_files(self, extraction_results: List[ContentExtractionResult]) -&gt; CorrelationResult:\n    \"\"\"Correlate information across multiple files\"\"\"\n\n    correlations = []\n    conflicts = []\n\n    for i, result1 in enumerate(extraction_results):\n        for j, result2 in enumerate(extraction_results[i+1:], i+1):\n            # Compare extracted data\n            correlation = self._compare_extracted_data(result1, result2)\n            correlations.append(correlation)\n\n            # Detect conflicts\n            if correlation.conflict_score &gt; 0.7:\n                conflicts.append(Conflict(\n                    file1_id=result1.file_id,\n                    file2_id=result2.file_id,\n                    conflict_type=correlation.conflict_type,\n                    description=correlation.conflict_description\n                ))\n\n    return CorrelationResult(\n        correlations=correlations,\n        conflicts=conflicts,\n        overall_consistency=1.0 - (len(conflicts) / len(correlations)) if correlations else 1.0\n    )\n</code></pre>"},{"location":"flows/document-analysis.html#processor-selection","title":"Processor Selection","text":""},{"location":"flows/document-analysis.html#form-parser-default","title":"Form Parser (Default)","text":"<ul> <li>Use Case: General documents, utility bills, forms</li> <li>Cost: $30/1,000 pages</li> <li>Features: Key-value extraction, table recognition, layout analysis</li> <li>Best For: Most document types</li> </ul>"},{"location":"flows/document-analysis.html#utility-parser-specialized","title":"Utility Parser (Specialized)","text":"<ul> <li>Use Case: Utility bills specifically</li> <li>Cost: $0.10 per 10 pages</li> <li>Features: Utility-specific fields, usage history, billing periods</li> <li>Best For: Electricity, gas, water bills</li> </ul>"},{"location":"flows/document-analysis.html#layout-parser","title":"Layout Parser","text":"<ul> <li>Use Case: Structured documents with complex layouts</li> <li>Cost: $10/1,000 pages</li> <li>Features: Text segmentation, table extraction, document structure</li> <li>Best For: Reports, statements, multi-column documents</li> </ul>"},{"location":"flows/document-analysis.html#enterprise-ocr","title":"Enterprise OCR","text":"<ul> <li>Use Case: Image-only documents</li> <li>Cost: $1.50/1,000 pages</li> <li>Features: High-accuracy OCR, text recognition</li> <li>Best For: Scanned documents, photos</li> </ul>"},{"location":"flows/document-analysis.html#output-formats","title":"Output Formats","text":""},{"location":"flows/document-analysis.html#tampering-result","title":"Tampering Result","text":"<pre><code>{\n  \"file_id\": \"f_001\",\n  \"score\": 78.4,\n  \"decision\": \"likely_tampered\",\n  \"indicators\": [\n    \"handwritten overlay in numeric cell\",\n    \"texture mismatch vs surrounding digits\",\n    \"incremental edit artifacts\"\n  ],\n  \"confidence\": 0.92\n}\n</code></pre>"},{"location":"flows/document-analysis.html#content-extraction-result","title":"Content Extraction Result","text":"<pre><code>{\n  \"file_id\": \"f_001\",\n  \"pages\": [\n    {\n      \"page\": 1,\n      \"kv\": [\n        {\n          \"key\": \"Usage (kWh)\",\n          \"value\": \"7833\",\n          \"bbox\": [x1, y1, x2, y2],\n          \"confidence\": 0.93\n        }\n      ],\n      \"tables\": [\n        {\n          \"name\": \"Usage history\",\n          \"rows\": [\n            {\"month\": \"Apr 2025\", \"kwh\": \"2410\"},\n            {\"month\": \"May 2025\", \"kwh\": \"2613\"},\n            {\"month\": \"Jun 2025\", \"kwh\": \"2810\"}\n          ],\n          \"bbox\": [x1, y1, x2, y2],\n          \"confidence\": 0.91\n        }\n      ],\n      \"text\": \"extracted text content\"\n    }\n  ],\n  \"confidence\": 0.89\n}\n</code></pre>"},{"location":"flows/document-analysis.html#correlation-result","title":"Correlation Result","text":"<pre><code>{\n  \"correlations\": [\n    {\n      \"file1_id\": \"f_001\",\n      \"file2_id\": \"f_002\",\n      \"similarity_score\": 0.85,\n      \"conflict_score\": 0.1,\n      \"matching_fields\": [\"account_number\", \"service_period\"],\n      \"conflicting_fields\": []\n    }\n  ],\n  \"conflicts\": [],\n  \"overall_consistency\": 0.95\n}\n</code></pre>"},{"location":"flows/document-analysis.html#quality-gates","title":"Quality Gates","text":""},{"location":"flows/document-analysis.html#tampering-thresholds","title":"Tampering Thresholds","text":"<ul> <li>Clean: Score &lt; 30</li> <li>Suspicious: Score 30-60</li> <li>Likely Tampered: Score &gt; 60</li> </ul>"},{"location":"flows/document-analysis.html#content-extraction-thresholds","title":"Content Extraction Thresholds","text":"<ul> <li>High Confidence: &gt; 0.8</li> <li>Medium Confidence: 0.5-0.8</li> <li>Low Confidence: &lt; 0.5</li> </ul>"},{"location":"flows/document-analysis.html#correlation-thresholds","title":"Correlation Thresholds","text":"<ul> <li>High Consistency: &gt; 0.8</li> <li>Medium Consistency: 0.5-0.8</li> <li>Low Consistency: &lt; 0.5</li> </ul>"},{"location":"flows/document-analysis.html#error-handling","title":"Error Handling","text":""},{"location":"flows/document-analysis.html#file-processing-errors","title":"File Processing Errors","text":"<ul> <li>Invalid Format: Skip file with error message</li> <li>Corrupted File: Attempt recovery or skip</li> <li>Size Limits: Reject oversized files</li> <li>Security Issues: Quarantine suspicious files</li> </ul>"},{"location":"flows/document-analysis.html#api-errors","title":"API Errors","text":"<ul> <li>Resistant AI: Fallback to basic validation</li> <li>Document AI: Retry with different processor</li> <li>Network Issues: Implement retry logic</li> <li>Rate Limits: Queue requests and retry</li> </ul>"},{"location":"flows/document-analysis.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"flows/document-analysis.html#parallel-processing","title":"Parallel Processing","text":"<ul> <li>Multi-file: Process multiple files simultaneously</li> <li>Multi-page: Process pages in parallel</li> <li>API Calls: Batch API requests when possible</li> </ul>"},{"location":"flows/document-analysis.html#caching-strategy","title":"Caching Strategy","text":"<ul> <li>File Hashes: Cache results by file hash</li> <li>Processor Results: Cache extraction results</li> <li>Tampering Results: Cache tampering analysis</li> </ul>"},{"location":"flows/document-analysis.html#resource-management","title":"Resource Management","text":"<ul> <li>Memory Usage: Monitor and limit memory consumption</li> <li>CPU Usage: Distribute processing across cores</li> <li>Network Usage: Optimize API call patterns</li> </ul>"},{"location":"flows/document-analysis.html#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"flows/document-analysis.html#key-metrics","title":"Key Metrics","text":"<ul> <li>Processing Time: Average time per file</li> <li>Success Rate: Percentage of successful extractions</li> <li>Accuracy: Comparison with manual validation</li> <li>Cost per File: Track processing costs</li> </ul>"},{"location":"flows/document-analysis.html#alerts","title":"Alerts","text":"<ul> <li>High Tampering Rate: Alert when tampering rate exceeds threshold</li> <li>Extraction Failures: Alert when extraction success rate drops</li> <li>API Errors: Alert when API error rate increases</li> <li>Processing Delays: Alert when processing time exceeds SLA</li> </ul>"},{"location":"flows/document-analysis.html#integration-points","title":"Integration Points","text":""},{"location":"flows/document-analysis.html#input-sources","title":"Input Sources","text":"<ul> <li>File Upload Service: Source of files to process</li> <li>Validation Service: File format validation</li> <li>Storage Service: File storage and retrieval</li> </ul>"},{"location":"flows/document-analysis.html#output-destinations","title":"Output Destinations","text":"<ul> <li>Scoring Engine: Provides tampering and extraction scores</li> <li>Audit Log: Records processing results</li> <li>Notification System: Alerts for high tampering scores</li> </ul>"},{"location":"flows/document-analysis.html#future-enhancements","title":"Future Enhancements","text":""},{"location":"flows/document-analysis.html#advanced-features","title":"Advanced Features","text":"<ul> <li>Custom Processors: Train domain-specific models</li> <li>Real-time Processing: Stream processing for immediate results</li> <li>Mobile Integration: Support mobile document capture</li> <li>Blockchain Verification: Immutable document verification</li> </ul>"},{"location":"flows/document-analysis.html#performance-improvements","title":"Performance Improvements","text":"<ul> <li>Edge Processing: Process documents closer to users</li> <li>GPU Acceleration: Use GPUs for faster processing</li> <li>Predictive Caching: Pre-process likely documents</li> <li>Smart Routing: Route to optimal processors automatically</li> </ul>"},{"location":"flows/text-qa.html","title":"Text Q&amp;A Flow","text":"<p>Goal: Detect anomalies in long-form textual answers compared with historical distributions; provide an accurate answer + confidence.</p> <p>Inputs: question, historical answers. Outputs: answer, confidence, evidence excerpts.</p>"},{"location":"flows/text-qa.html#overview","title":"Overview","text":"<p>The Text Q&amp;A Flow analyzes the provided answer against historical data for the same question to identify if the current answer is anomalous. This flow is essential for detecting patterns and inconsistencies in textual responses over time.</p>"},{"location":"flows/text-qa.html#components","title":"Components","text":""},{"location":"flows/text-qa.html#1-historical-data-retrieval","title":"1. Historical Data Retrieval","text":"<ul> <li>Purpose: Fetch all previous answers for the question ID</li> <li>Data Source: Historical answers database</li> <li>Retrieval Logic: Get answers from the last 100 submissions for the same question</li> <li>Filtering: Apply time-based and quality filters</li> </ul>"},{"location":"flows/text-qa.html#2-statistical-analysis-engine","title":"2. Statistical Analysis Engine","text":"<ul> <li>Purpose: Calculate statistical measures from historical data</li> <li>Metrics: Mean, standard deviation, outliers, distribution analysis</li> <li>Algorithms: Z-score analysis, percentile ranking, trend analysis</li> <li>Output: Statistical summary with confidence intervals</li> </ul>"},{"location":"flows/text-qa.html#3-pattern-recognition","title":"3. Pattern Recognition","text":"<ul> <li>Purpose: Detect patterns and anomalies in answer patterns</li> <li>Techniques: Machine learning models, NLP analysis, semantic similarity</li> <li>Features: Answer length, vocabulary, sentiment, structure</li> <li>Output: Pattern analysis with anomaly indicators</li> </ul>"},{"location":"flows/text-qa.html#4-anomaly-scoring","title":"4. Anomaly Scoring","text":"<ul> <li>Purpose: Generate a 0-100 score indicating anomaly level</li> <li>Scoring Method: Weighted combination of statistical and pattern scores</li> <li>Thresholds: </li> <li>0-30: Normal</li> <li>30-60: Suspicious</li> <li>60-100: Anomalous</li> <li>Output: Anomaly score with explanation</li> </ul>"},{"location":"flows/text-qa.html#process-flow","title":"Process Flow","text":""},{"location":"flows/text-qa.html#step-1-data-retrieval","title":"Step 1: Data Retrieval","text":"<pre><code>async def _get_historical_answers(self, question_id: str) -&gt; List[str]:\n    \"\"\"Retrieve historical answers for the question\"\"\"\n    query = \"\"\"\n    SELECT answer, created_at, confidence_score \n    FROM historical_answers \n    WHERE question_id = %s \n    ORDER BY created_at DESC \n    LIMIT 100\n    \"\"\"\n    return await self.db.fetch_all(query, (question_id,))\n</code></pre>"},{"location":"flows/text-qa.html#step-2-statistical-analysis","title":"Step 2: Statistical Analysis","text":"<pre><code>def analyze_statistical_patterns(self, current_answer: str, historical_answers: List[str]) -&gt; StatisticalResult:\n    \"\"\"Perform statistical analysis on historical data\"\"\"\n\n    # Calculate basic statistics\n    answer_lengths = [len(answer) for answer in historical_answers]\n    current_length = len(current_answer)\n\n    # Z-score analysis\n    mean_length = statistics.mean(answer_lengths)\n    std_length = statistics.stdev(answer_lengths)\n    z_score = (current_length - mean_length) / std_length if std_length &gt; 0 else 0\n\n    # Percentile ranking\n    percentile = stats.percentileofscore(answer_lengths, current_length)\n\n    return StatisticalResult(\n        mean=mean_length,\n        std=std_length,\n        z_score=z_score,\n        percentile=percentile,\n        anomaly_score=abs(z_score) * 20  # Scale to 0-100\n    )\n</code></pre>"},{"location":"flows/text-qa.html#step-3-pattern-recognition","title":"Step 3: Pattern Recognition","text":"<pre><code>def detect_patterns(self, current_answer: str, historical_answers: List[str]) -&gt; PatternResult:\n    \"\"\"Detect patterns and anomalies in answer structure\"\"\"\n\n    # Semantic similarity analysis\n    similarities = []\n    for hist_answer in historical_answers:\n        similarity = self.calculate_semantic_similarity(current_answer, hist_answer)\n        similarities.append(similarity)\n\n    # Vocabulary analysis\n    current_vocab = set(current_answer.lower().split())\n    hist_vocab = set()\n    for answer in historical_answers:\n        hist_vocab.update(answer.lower().split())\n\n    vocab_overlap = len(current_vocab.intersection(hist_vocab)) / len(current_vocab.union(hist_vocab))\n\n    # Sentiment analysis\n    current_sentiment = self.analyze_sentiment(current_answer)\n    hist_sentiments = [self.analyze_sentiment(answer) for answer in historical_answers]\n    sentiment_deviation = abs(current_sentiment - statistics.mean(hist_sentiments))\n\n    return PatternResult(\n        semantic_similarity=statistics.mean(similarities),\n        vocab_overlap=vocab_overlap,\n        sentiment_deviation=sentiment_deviation,\n        anomaly_score=self.calculate_pattern_anomaly_score(similarities, vocab_overlap, sentiment_deviation)\n    )\n</code></pre>"},{"location":"flows/text-qa.html#step-4-score-calculation","title":"Step 4: Score Calculation","text":"<pre><code>def _calculate_anomaly_score(self, stats: StatisticalResult, patterns: PatternResult) -&gt; float:\n    \"\"\"Calculate anomaly score based on statistical and pattern analysis\"\"\"\n    # Weighted combination of statistical and pattern scores\n    statistical_weight = 0.7\n    pattern_weight = 0.3\n\n    return (stats.anomaly_score * statistical_weight + \n            patterns.anomaly_score * pattern_weight)\n</code></pre>"},{"location":"flows/text-qa.html#output-format","title":"Output Format","text":""},{"location":"flows/text-qa.html#text-anomaly-result","title":"Text Anomaly Result","text":"<pre><code>{\n  \"score\": 22.0,\n  \"label\": \"normal\",\n  \"explanation\": \"Answer falls within expected range based on historical data\",\n  \"confidence\": 0.85,\n  \"statistical_analysis\": {\n    \"mean_length\": 150,\n    \"std_length\": 25,\n    \"z_score\": 0.8,\n    \"percentile\": 75\n  },\n  \"pattern_analysis\": {\n    \"semantic_similarity\": 0.82,\n    \"vocab_overlap\": 0.75,\n    \"sentiment_deviation\": 0.1\n  }\n}\n</code></pre>"},{"location":"flows/text-qa.html#quality-gates","title":"Quality Gates","text":""},{"location":"flows/text-qa.html#confidence-thresholds","title":"Confidence Thresholds","text":"<ul> <li>High Confidence: &gt; 0.8</li> <li>Medium Confidence: 0.5 - 0.8</li> <li>Low Confidence: &lt; 0.5</li> </ul>"},{"location":"flows/text-qa.html#anomaly-thresholds","title":"Anomaly Thresholds","text":"<ul> <li>Normal: Score &lt; 30</li> <li>Suspicious: Score 30-60</li> <li>Anomalous: Score &gt; 60</li> </ul>"},{"location":"flows/text-qa.html#data-requirements","title":"Data Requirements","text":"<ul> <li>Minimum Historical Data: 10 previous answers</li> <li>Maximum Historical Data: 100 previous answers</li> <li>Time Window: Last 12 months</li> <li>Quality Filter: Exclude answers with confidence &lt; 0.5</li> </ul>"},{"location":"flows/text-qa.html#error-handling","title":"Error Handling","text":""},{"location":"flows/text-qa.html#insufficient-historical-data","title":"Insufficient Historical Data","text":"<pre><code>if not historical_answers:\n    return TextAnomalyResult(\n        score=0.0,\n        label=\"normal\",\n        explanation=\"No historical data available for comparison\",\n        confidence=0.0\n    )\n</code></pre>"},{"location":"flows/text-qa.html#data-quality-issues","title":"Data Quality Issues","text":"<ul> <li>Missing Data: Handle gracefully with default values</li> <li>Corrupted Data: Skip problematic entries</li> <li>Outdated Data: Apply time-based filtering</li> </ul>"},{"location":"flows/text-qa.html#performance-optimization","title":"Performance Optimization","text":""},{"location":"flows/text-qa.html#caching-strategy","title":"Caching Strategy","text":"<ul> <li>Historical Data Cache: Cache recent historical data for 1 hour</li> <li>Statistical Results Cache: Cache calculated statistics for 30 minutes</li> <li>Pattern Analysis Cache: Cache pattern analysis for 15 minutes</li> </ul>"},{"location":"flows/text-qa.html#batch-processing","title":"Batch Processing","text":"<ul> <li>Multiple Questions: Process multiple questions in parallel</li> <li>Bulk Updates: Update historical data in batches</li> <li>Async Processing: Use async/await for database operations</li> </ul>"},{"location":"flows/text-qa.html#monitoring-and-metrics","title":"Monitoring and Metrics","text":""},{"location":"flows/text-qa.html#key-metrics","title":"Key Metrics","text":"<ul> <li>Processing Time: Average time per analysis</li> <li>Accuracy: Comparison with human review</li> <li>False Positive Rate: Incorrect anomaly detections</li> <li>False Negative Rate: Missed anomalies</li> </ul>"},{"location":"flows/text-qa.html#alerts","title":"Alerts","text":"<ul> <li>High Anomaly Rate: Alert when anomaly rate exceeds threshold</li> <li>Processing Delays: Alert when processing time exceeds SLA</li> <li>Data Quality Issues: Alert when historical data quality drops</li> </ul>"},{"location":"flows/text-qa.html#integration-points","title":"Integration Points","text":""},{"location":"flows/text-qa.html#input-sources","title":"Input Sources","text":"<ul> <li>Question Database: Source of question IDs and metadata</li> <li>Historical Answers: Source of previous answers</li> <li>User Submissions: Current answer to analyze</li> </ul>"},{"location":"flows/text-qa.html#output-destinations","title":"Output Destinations","text":"<ul> <li>Scoring Engine: Provides text anomaly score</li> <li>Audit Log: Records analysis results</li> <li>Notification System: Alerts for high anomaly scores</li> </ul>"},{"location":"flows/text-qa.html#future-enhancements","title":"Future Enhancements","text":""},{"location":"flows/text-qa.html#machine-learning-improvements","title":"Machine Learning Improvements","text":"<ul> <li>Custom Models: Train domain-specific models</li> <li>Ensemble Methods: Combine multiple analysis techniques</li> <li>Online Learning: Update models with new data</li> </ul>"},{"location":"flows/text-qa.html#advanced-analytics","title":"Advanced Analytics","text":"<ul> <li>Trend Analysis: Detect long-term trends in answers</li> <li>Seasonal Patterns: Account for seasonal variations</li> <li>Cross-Question Analysis: Analyze patterns across related questions</li> </ul>"}]}